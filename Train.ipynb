{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOEW7ULnk9Ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgByixwSzAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "b894ba09-05e6-43ad-b72c-6f4ebafea8f2"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQMWsh9GT-5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 512\n",
        "NUM_IMGS = 10\n",
        "task_path = \"drive/My Drive/test_task/\"\n",
        "data_path = task_path + \"data/\"\n",
        "checkpoints_path = task_path + \"checkpoints/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7xQiIYFnghH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "10946735-07c3-4682-b90a-5f0a1cdf04f1"
      },
      "source": [
        "descr = json.load(open(data_path + \"label_descriptions.json\", \"rb\"))\n",
        "label_names = [cat[\"name\"] for cat in descr[\"categories\"]]\n",
        "NUM_CLASSES = len(descr['categories']) + 1 # plus background\n",
        "print(f\"Number of attributes : {len(descr['attributes'])}\")\n",
        "print(f\"Number of categoriees : {len(descr['categories'])}\")\n",
        "print(f\"Number of classes to predict : {NUM_CLASSES}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of attributes : 92\n",
            "Number of categoriees : 46\n",
            "Number of classes to predict : 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtNynGr6hwNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(data_path + \"10images.csv\")\n",
        "df[\"ClassId\"] = df[\"ClassId\"].apply(lambda x: int(x.split('_')[0]) + 1) # use only categories as classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVn1XjTFB6Ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_images(df):\n",
        "  # get each image (as multiple segments) in a saparate dataframe\n",
        "  imgs = []\n",
        "  for img_name in df[\"ImageId\"].unique():\n",
        "    imgs.append(df.loc[df[\"ImageId\"] == img_name])\n",
        "  return imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aXdwHqQS-7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def segments2labeled(segments):\n",
        "  # converts dataframe with segments to labeled image\n",
        "  h, w = segments[\"Height\"].iloc[0], segments[\"Width\"].iloc[0]\n",
        "\n",
        "  flat = np.full(h * w, 0)\n",
        "  for index, row in segments.iterrows():\n",
        "    pixels = [int(p) for p in row[\"EncodedPixels\"].split()]\n",
        "    \n",
        "    class_id = row[\"ClassId\"] # int(row[\"ClassId\"].split('_')[0]) + 1\n",
        "\n",
        "    for i in range(0, len(pixels), 2):\n",
        "      start = pixels[i] - 1\n",
        "      flat[start: start + pixels[i+1]] = class_id\n",
        "    \n",
        "  labeled_img = flat.reshape((h, w), order='F')\n",
        "  final_img = cv2.resize(labeled_img, \n",
        "                         (IMG_SIZE, IMG_SIZE), \n",
        "                         interpolation=cv2.INTER_NEAREST)\n",
        "  return final_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lO64GDHhMJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def labeled2masked(labeled):\n",
        "  # converts labeled 2d image to 3d array of masks\n",
        "  labels = np.unique(labeled)\n",
        "  labels = labels[labels != 0] # except zero (background)\n",
        "  rois = list()\n",
        "  mask = np.zeros((*labeled.shape, len(labels)))\n",
        "  for i, label in enumerate(labels):\n",
        "    segment = labeled == label\n",
        "    mask[:, :, i][segment] = 1\n",
        "\n",
        "    mask_pos = np.where(segment) # find locations of boundary boxes\n",
        "    y1, x1 = np.min(mask_pos, axis=1)\n",
        "    y2, x2 = np.max(mask_pos, axis=1)\n",
        "\n",
        "    rois.append([y1, x1, y2, x2])\n",
        "\n",
        "  return mask, labels, np.array(rois)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qKtJ18RVev-",
        "colab_type": "text"
      },
      "source": [
        "Save reshaped and annotated images in two folders (for PSPNet)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuEAgGvGhwIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image_segments in get_images(df):\n",
        "  img_name = image_segments[\"ImageId\"].iloc[0]\n",
        "  annotated_img = segments2labeled(image_segments) # labeled == annotated\n",
        "  png_name = img_name.split('.')[0] + \".png\"\n",
        "  cv2.imwrite(f\"{data_path}annotated/{png_name}\", annotated_img)\n",
        "\n",
        "  img = cv2.imread(f\"{data_path}{NUM_IMGS}images/{img_name}\")\n",
        "  reshaped_img = cv2.resize(img, \n",
        "                            (IMG_SIZE, IMG_SIZE), \n",
        "                            interpolation=cv2.INTER_NEAREST)\n",
        "  cv2.imwrite(data_path + f\"10reshaped/{png_name}\", reshaped_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yt0iVXEO5k8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e85f2950-0686-4ca2-93d6-fbbe86848085"
      },
      "source": [
        "!git clone https://www.github.com/divamgupta/image-segmentation-keras.git\n",
        "os.chdir(\"image-segmentation-keras\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'image-segmentation-keras' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moqr9zF9Sr3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c9e300b-3619-4a5e-b526-79f83250b321"
      },
      "source": [
        "from keras_segmentation.models.model_utils import transfer_weights\n",
        "from keras_segmentation.pretrained import pspnet_50_ADE_20K\n",
        "from keras_segmentation.models.pspnet import pspnet_50"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D8b1Ij7S-ql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "9eb0b766-3604-4751-aa25-ab227e4c8a18"
      },
      "source": [
        "pretrained_model = pspnet_50_ADE_20K()\n",
        "pspnet = pspnet_50(n_classes=NUM_CLASSES)\n",
        "\n",
        "transfer_weights(pretrained_model, pspnet)\n",
        "# pspnet.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying weights \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "225it [01:54,  1.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Copied weights of 120 layers and skipped 1 layers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHrnFxG9hv1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "4b0f56b9-4fa3-47d6-b695-3cf87269c4bb"
      },
      "source": [
        "pspnet.train(\n",
        "    train_images =  \"../\" + data_path + \"10reshaped/\",\n",
        "    train_annotations =  \"../\" + data_path + \"annotated/\",\n",
        "    checkpoints_path = \"../\" + checkpoints_path, \n",
        "    epochs=1\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 85.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Verifying training dataset\n",
            "Dataset verified! \n",
            "Starting Epoch  0\n",
            "Epoch 1/1\n",
            "512/512 [==============================] - 235s 458ms/step - loss: 0.0741 - acc: 0.9828\n",
            "saved  ../drive/My Drive/test_task/checkpoints/.model.0\n",
            "Finished Epoch 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uSRrvrDc2h_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pspnet.save_weights(f\"../{checkpoints_path}pspnet_model_checkpoint\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKYodOU6gLjl",
        "colab_type": "text"
      },
      "source": [
        "Load pretrained Mask RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvpmpKoSMVZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1202e8d6-e93d-47a6-f35b-71bc91e15e7c"
      },
      "source": [
        "os.chdir(\"..\")\n",
        "!git clone https://www.github.com/matterport/Mask_RCNN.git\n",
        "os.chdir(\"Mask_RCNN\")\n",
        "!wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Mask_RCNN' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDAqhTQRedKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mrcnn import visualize\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import utils\n",
        "from mrcnn.config import Config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4saXGKmjjSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Fashionista(utils.Dataset):\n",
        "  def __init__(self, df):\n",
        "    super().__init__(self)\n",
        "    \n",
        "    for i in range(NUM_CLASSES - 1):\n",
        "        self.add_class(\"fashionista\", i + 1, label_names[i])\n",
        "    \n",
        "    for i, img_segments in enumerate(get_images(df)):\n",
        "        self.add_image(\"fashionista\", \n",
        "                      image_id=i, \n",
        "                      path=f\"../{data_path}{NUM_IMGS}images/{img_segments['ImageId'].iloc[0]}\", \n",
        "                      labels=img_segments[\"ClassId\"],\n",
        "                      annotations=img_segments[\"EncodedPixels\"], \n",
        "                      height=img_segments[\"Height\"].iloc[0], \n",
        "                      width=img_segments[\"Width\"].iloc[0],\n",
        "                      img_segments=img_segments)\n",
        "        \n",
        "  def load_image(self, img_id):\n",
        "    img = cv2.imread(self.image_info[img_id][\"path\"])\n",
        "    return cv2.resize(img, \n",
        "                      (IMG_SIZE, IMG_SIZE), \n",
        "                      interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "      \n",
        "  def load_mask(self, image_id):\n",
        "    info = self.image_info[image_id]\n",
        "    labeled = segments2labeled(info[\"img_segments\"])\n",
        "    mask, labels, _ = labeled2masked(labeled)\n",
        "    return mask, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myemEilw4eut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = Fashionista(df)\n",
        "dataset.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0pU3dI_jhON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FashionConfig(Config):\n",
        "    NAME = \"fashionista\"\n",
        "    NUM_CLASSES = NUM_CLASSES \n",
        "\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    \n",
        "    IMAGE_MIN_DIM = IMG_SIZE\n",
        "    IMAGE_MAX_DIM = IMG_SIZE \n",
        "    STEPS_PER_EPOCH = 1000\n",
        "    \n",
        "config = FashionConfig()\n",
        "# config.display()\n",
        "mrcnn_model = modellib.MaskRCNN(mode=\"training\", config=config, \n",
        "                                model_dir=\"../\" + checkpoints_path)\n",
        "\n",
        "mrcnn_model.load_weights(\"mask_rcnn_coco.h5\", by_name=True, exclude=[\n",
        "    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fm6kD2RjjQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0c72905-4f9f-4536-bc4a-c639dd259c1d"
      },
      "source": [
        "mrcnn_model.train(dataset, dataset,\n",
        "            learning_rate=1e-2,\n",
        "            epochs=1,\n",
        "            layers=\"all\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.01\n",
            "\n",
            "Checkpoint Path: ../drive/My Drive/test_task/checkpoints/fashionista20191215T1553/mask_rcnn_fashionista_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n",
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1000/1000 [==============================] - 358s 358ms/step - loss: 1.6248 - rpn_class_loss: 0.0598 - rpn_bbox_loss: 1.0193 - mrcnn_class_loss: 0.1484 - mrcnn_bbox_loss: 0.2334 - mrcnn_mask_loss: 0.1639 - val_loss: 0.9484 - val_rpn_class_loss: 0.0081 - val_rpn_bbox_loss: 0.7091 - val_mrcnn_class_loss: 0.0400 - val_mrcnn_bbox_loss: 0.1030 - val_mrcnn_mask_loss: 0.0882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17QApDe3PFfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"..\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}